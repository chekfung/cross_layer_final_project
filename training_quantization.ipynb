{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chekfung/cross_layer_final_project/blob/main/training_quantization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWCSJNoXXjMU"
      },
      "source": [
        "# Source Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJuqknGwXjMW"
      },
      "source": [
        "## Imports Needed Throughout the Project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "B-AzI0DdXjMY"
      },
      "outputs": [],
      "source": [
        "# All Imports \n",
        "import sys\n",
        "import numpy as np\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "from google.colab import files\n",
        "\n",
        "# argument parser\n",
        "import easydict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ItgEiUWPXjMa"
      },
      "source": [
        "## Get and Download Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "wWPbK4uKXjMb"
      },
      "outputs": [],
      "source": [
        "# MNIST Dataset (Images and Labels)\n",
        "train_set = dsets.FashionMNIST(\n",
        "    root = './data/FashionMNIST',\n",
        "    train = True,\n",
        "    download = True,\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor()                                 \n",
        "    ])\n",
        ")\n",
        "\n",
        "test_set = dsets.FashionMNIST(\n",
        "    root = './data/FashionMNIST',\n",
        "    train = False,\n",
        "    download = True,\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor()                                 \n",
        "    ])\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOYytU77XjMc"
      },
      "source": [
        "## More Helper Code for Training and Testing Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "QcNG3HYC7dJk"
      },
      "outputs": [],
      "source": [
        "def fuse_conv_bn(model,out_model):\n",
        "\n",
        "  conv_layer = None\n",
        "  count = 0\n",
        "\n",
        "  # 1. for loop to collect all Conv layers\n",
        "  # 2. for loop to collect all BatchNorm layers\n",
        "  for layer in model.modules():\n",
        "    \n",
        "    if isinstance(layer, nn.BatchNorm2d):\n",
        "\n",
        "      conv_size = conv_layer.weight.size()\n",
        "\n",
        "\n",
        "      with torch.no_grad():\n",
        "        for i in range(conv_size[0]):\n",
        "\n",
        "          \n",
        "          # get the conv2d weights\n",
        "          weights = conv_layer.weight[i]\n",
        "\n",
        "\n",
        "          denominator = torch.sqrt(layer.eps+layer.running_var)\n",
        "          gamma = layer.weight[i]\n",
        "          beta = layer.bias[i]\n",
        "          \n",
        "\n",
        "          for j in range(conv_size[1]):\n",
        "            for k in range(conv_size[2]):\n",
        "              for l in range(conv_size[3]):\n",
        "                # update out_model layer[count]\n",
        "\n",
        "                if count == 0:\n",
        "                  out_model.conv1.weight[i][j][k][l] = gamma * conv_layer.weight[i][j][k][l]  / denominator[i]  \n",
        "                else:\n",
        "                  out_model.conv2.weight[i][j][k][l] = gamma * conv_layer.weight[i][j][k][l]  / denominator[i]  \n",
        "\n",
        "          # In i loop for bias since only 1D\n",
        "          if count == 0:\n",
        "            out_model.conv1.bias[i] = (gamma * (conv_layer.bias[i] - layer.running_mean[i])  / denominator[i]) + beta\n",
        "          else:\n",
        "            out_model.conv2.bias[i] = (gamma * (conv_layer.bias[i] - layer.running_mean[i])  / denominator[i]) + beta\n",
        "\n",
        "        count += 1\n",
        "\n",
        "    conv_layer = layer # conv2d\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzSo2kcrXjMe"
      },
      "source": [
        "## FP32 Model "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "vlRcw7IMXjMg"
      },
      "outputs": [],
      "source": [
        "class MyConvNet_FP32(nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super(MyConvNet_FP32, self).__init__()\n",
        "        # Layer 1\n",
        "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn1   = nn.BatchNorm2d(16)\n",
        "        self.act1  = nn.ReLU(inplace=True)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        # Layer 2\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn2   = nn.BatchNorm2d(32)\n",
        "        self.act2  = nn.ReLU(inplace=True)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        # Layer 3\n",
        "        self.lin2  = nn.Linear(7*7*32, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Layer 1\n",
        "        c1 = self.conv1(x)\n",
        "        b1  = self.bn1(c1)\n",
        "        a1  = self.act1(b1)\n",
        "        p1  = self.pool1(a1)\n",
        "\n",
        "        # Layer 2\n",
        "        c2  = self.conv2(p1)\n",
        "        b2  = self.bn2(c2)\n",
        "        a2  = self.act2(b2)\n",
        "        p2  = self.pool2(a2)\n",
        "\n",
        "        # Flatten and Layer 3\n",
        "        flt = p2.view(p2.size(0), -1)\n",
        "        out = self.lin2(flt)\n",
        "        return out\n",
        "  \n",
        "# model = MyConvNet(args)\n",
        "# model = model.cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlSJ4lJwXjMh"
      },
      "source": [
        "## Quantization Helper Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "I57BN8KQXjMi"
      },
      "outputs": [],
      "source": [
        "def simple_quantize_val(val, scale_factor, min_val, max_val):\n",
        "  value = torch.round(val / scale_factor)\n",
        "\n",
        "  if (value < min_val):\n",
        "    value = min_val\n",
        "\n",
        "  if (value > max_val):\n",
        "    value = max_val\n",
        "\n",
        "  return (value * scale_factor)\n",
        "\n",
        "def fixed_point_quantize_val(val, num_bits, fractional_bits):\n",
        "  integer_bits = num_bits - fractional_bits - 1 # Subtract one for sign bit\n",
        "  smallest_step_size = 1 / np.power(2, fractional_bits)\n",
        "  largest_number = (np.power(2, integer_bits) - 1) + ((np.power(2, fractional_bits)-1) * smallest_step_size)\n",
        "  smallest_number = -1 * np.power(2, integer_bits)\n",
        "\n",
        "  value = torch.round(val / smallest_step_size) * smallest_step_size\n",
        "\n",
        "  if (value < smallest_number):\n",
        "    value = smallest_number\n",
        "\n",
        "  if (value > largest_number):\n",
        "    value = largest_number\n",
        "\n",
        "  return value\n",
        "\n",
        "# Perhaps slightly optimized version?\n",
        "def fixed_point_quantize_faster(val, smallest_step_size, largest_number, smallest_number):\n",
        "\n",
        "  # Perform Pseudo Quantization\n",
        "  value = torch.round(val / smallest_step_size) * smallest_step_size\n",
        "\n",
        "  # Clamp Values\n",
        "  if (value < smallest_number):\n",
        "    value = smallest_number\n",
        "\n",
        "  if (value > largest_number):\n",
        "    value = largest_number\n",
        "\n",
        "  return value\n",
        "\n",
        "### NOTE: ONLY USE THIS SHIT ###\n",
        "def optimized_tensor_fp_quantize(tens, step_size, largest_num, smallest_num):\n",
        "  # Do everything in tensor operations\n",
        "  new_tensor = torch.round(tens / step_size) * step_size\n",
        "  torch.clamp(new_tensor, min=smallest_num, max=largest_num) \n",
        "  return new_tensor\n",
        "\n",
        "# Right now, only for integer quantization.\n",
        "def quantize_fp_model_weights(model):\n",
        "  count = 0\n",
        "  for layer in model.modules():\n",
        "    if not isinstance(layer, (nn.ReLU, nn.MaxPool2d)) and count != 0:\n",
        "        \n",
        "      with torch.no_grad():\n",
        "        layer.weight.data = optimized_tensor_fp_quantize(layer.weight.data, model.weights_step_size, model.weights_largest_num_representable, model.weights_smallest_num_representable)\n",
        "\n",
        "    count += 1\n",
        "  \n",
        "  return 0\n",
        "\n",
        "def quantize_fp_model_biases(model):\n",
        "  count = 0\n",
        "  for layer in model.modules():\n",
        "    if not isinstance(layer, (nn.ReLU, nn.MaxPool2d)) and count != 0:\n",
        "        \n",
        "      with torch.no_grad():\n",
        "        layer.bias.data = optimized_tensor_fp_quantize(layer.bias.data, model.bias_step_size, model.bias_largest_num_representable, model.bias_smallest_num_representable)\n",
        "\n",
        "    count += 1\n",
        "  \n",
        "  return 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "ln6bdN1fXjMd"
      },
      "outputs": [],
      "source": [
        "def train_model(arg, model, criterion, optimizer, train_loader, quantize=False):\n",
        "    print(\"---Training started\")\n",
        "    # Training the Model\n",
        "    for epoch in range(arg.epochs):\n",
        "        for i, (images, labels) in enumerate(train_loader):\n",
        "            # Load Images into GPU\n",
        "            images = images.cuda()\n",
        "            labels = Variable(labels).cuda()\n",
        "\n",
        "            # Forward + Backward + Optimize\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            L1norm = model.parameters()\n",
        "            arr = []\n",
        "\n",
        "            # Calculate L1 Norm (if included in hyperparameters)\n",
        "            if arg.L1norm == True:\n",
        "                for name,param in model.named_parameters():\n",
        "                    if 'weight' in name.split('.'):\n",
        "                        arr.append(param)\n",
        "\n",
        "                L1loss = 0\n",
        "                for Losstmp in arr:\n",
        "                    L1loss = L1loss+Losstmp.abs().mean()\n",
        "\n",
        "                if len(arr) > 0:\n",
        "                    loss = loss+L1loss/len(arr)\n",
        "\n",
        "            if quantize:\n",
        "                # quantize loss\n",
        "                loss.data = optimized_tensor_fp_quantize(loss.data, model.loss_step_size, model.loss_largest_num_representable, model.loss_smallest_num_representable)\n",
        "\n",
        "            # Optimizer Step, Propagate Loss backwards\n",
        "            loss.backward()\n",
        "\n",
        "            if quantize:\n",
        "              \n",
        "                # quantize gradients\n",
        "                for name,param in model.named_parameters():\n",
        "                    # Print BEFORE Gradients\n",
        "                    # print(gradient)\n",
        "\n",
        "                    param.grad.data = optimized_tensor_fp_quantize(param.grad.data, model.gradient_step_size, model.gradient_largest_num_representable, model.gradient_smallest_num_representable)\n",
        "                    \n",
        "                    # Print AFTER Gradients\n",
        "                    # print(gradient)\n",
        "                \n",
        "            optimizer.step()\n",
        "\n",
        "            # # TODO: Need to quantize the biases as well.\n",
        "            if quantize:\n",
        "              quantize_fp_model_weights(model)\n",
        "              quantize_fp_model_biases(model)\n",
        "\n",
        "            if (i + 1) % 600 == 0:\n",
        "                print('Epoch: [% d/% d], Step: [% d/% d], Loss: %.4f'\n",
        "                        % (epoch + 1, arg.epochs, i + 1,\n",
        "                        len(train_set) // arg.batch_size, loss.data.item()))\n",
        "\n",
        "\n",
        "# Gets accuracy given dataset as well as total test loss\n",
        "def get_acc(model, criterion, test_loader, quantized=False):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for images, labels in test_loader:\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        outputs = model(images)\n",
        "        testloss = criterion(outputs, labels)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum()\n",
        "        break\n",
        "\n",
        "    if quantized:\n",
        "      testloss = optimized_tensor_fp_quantize(testloss, model.loss_step_size, model.loss_largest_num_representable, model.loss_smallest_num_representable)\n",
        "\n",
        "    return ((100 * correct / total), testloss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLM8kj7KXjMi"
      },
      "source": [
        "## Quantization Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "YQn2A92SXjMj"
      },
      "outputs": [],
      "source": [
        "# Assume that we always \n",
        "class MyConvNet_FIXED_POINT(nn.Module):\n",
        "    def __init__(self, args, forwardfp, gradientfp, lossfp, weightsfp, biasfp): #xfp's are tuples of the # of bits in the fp rep & # of fractional bits\n",
        "        super(MyConvNet_FIXED_POINT, self).__init__()\n",
        "\n",
        "\n",
        "        ### gradient FP Parameters ###\n",
        "        self.gradient_fp_bits = gradientfp[0]\n",
        "        self.gradient_int_bits = (gradientfp[0] - 1 - gradientfp[1])\n",
        "        self.gradient_fract_bits = gradientfp[1]\n",
        " \n",
        "        self.gradient_step_size = 1 / np.power(2, gradientfp[1])\n",
        "        self.gradient_largest_num_representable = (np.power(2, self.gradient_int_bits) - 1) + ((np.power(2, self.gradient_fract_bits)-1) * self.gradient_step_size)\n",
        "        self.gradient_smallest_num_representable = -1 * np.power(2, self.gradient_int_bits)\n",
        "        #########################\n",
        "\n",
        "        ### forward FP Parameters ###\n",
        "        self.forward_fp_bits = forwardfp[0]\n",
        "        self.forward_int_bits = (forwardfp[0] - 1 - forwardfp[1])\n",
        "        self.forward_fract_bits = forwardfp[1]\n",
        " \n",
        "        self.forward_step_size = 1 / np.power(2, forwardfp[1])\n",
        "        self.forward_largest_num_representable = (np.power(2, self.forward_int_bits) - 1) + ((np.power(2, self.forward_fract_bits)-1) * self.forward_step_size)\n",
        "        self.forward_smallest_num_representable = -1 * np.power(2, self.forward_int_bits)\n",
        "        #########################\n",
        "\n",
        "        ### Loss FP Parameters ###\n",
        "        self.loss_fp_bits = lossfp[0]\n",
        "        self.loss_int_bits = (lossfp[0] - 1 - lossfp[1])\n",
        "        self.loss_fract_bits = lossfp[1]\n",
        "\n",
        "        self.loss_step_size = 1 / np.power(2, lossfp[1])\n",
        "        self.loss_largest_num_representable = (np.power(2, self.loss_int_bits) - 1) + ((np.power(2, self.loss_fract_bits)-1) * self.loss_step_size)\n",
        "        self.loss_smallest_num_representable = -1 * np.power(2, self.loss_int_bits)\n",
        "        #########################\n",
        "\n",
        "        ### weights FP Parameters ###\n",
        "        self.weights_fp_bits = weightsfp[0]\n",
        "        self.weights_int_bits = (weightsfp[0] - 1 - weightsfp[1])\n",
        "        self.weights_fract_bits = weightsfp[1]\n",
        " \n",
        "        self.weights_step_size = 1 / np.power(2, weightsfp[1])\n",
        "        self.weights_largest_num_representable = (np.power(2, self.weights_int_bits) - 1) + ((np.power(2, self.weights_fract_bits)-1) * self.weights_step_size)\n",
        "        self.weights_smallest_num_representable = -1 * np.power(2, self.weights_int_bits)\n",
        "        #########################\n",
        "\n",
        "        ### bias FP Parameters ###\n",
        "        self.bias_fp_bits = biasfp[0]\n",
        "        self.bias_int_bits = (biasfp[0] - 1 - biasfp[1])\n",
        "        self.bias_fract_bits = biasfp[1]\n",
        " \n",
        "        self.bias_step_size = 1 / np.power(2, biasfp[1])\n",
        "        self.bias_largest_num_representable = (np.power(2, self.bias_int_bits) - 1) + ((np.power(2, self.bias_fract_bits)-1) * self.bias_step_size)\n",
        "        self.bias_smallest_num_representable = -1 * np.power(2, self.bias_int_bits)\n",
        "        #########################\n",
        "\n",
        "        # Layer 1\n",
        "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn1   = nn.BatchNorm2d(16)\n",
        "        self.act1  = nn.ReLU(inplace=True)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        # Layer 2\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn2   = nn.BatchNorm2d(32)\n",
        "        self.act2  = nn.ReLU(inplace=True)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        # Layer 3\n",
        "        self.lin2  = nn.Linear(7*7*32, 10)\n",
        "\n",
        "    # AUGMENT FORWARD PASS. forward pass not quantizes every single time we go through\n",
        "    def forward(self, x):\n",
        "        xq = optimized_tensor_fp_quantize(x, self.forward_step_size, self.forward_largest_num_representable, self.forward_smallest_num_representable)\n",
        "        # Layer 1\n",
        "        c1 = self.conv1(xq)\n",
        "        c1q = optimized_tensor_fp_quantize(c1, self.forward_step_size, self.forward_largest_num_representable, self.forward_smallest_num_representable)\n",
        "        b1  = self.bn1(c1q)\n",
        "        b1q = optimized_tensor_fp_quantize(b1, self.forward_step_size, self.forward_largest_num_representable, self.forward_smallest_num_representable)\n",
        "        a1  = self.act1(b1q)\n",
        "        p1  = self.pool1(a1)\n",
        " \n",
        "        # Layer 2\n",
        "        c2  = self.conv2(p1)\n",
        "        c2q = optimized_tensor_fp_quantize(c2, self.forward_step_size, self.forward_largest_num_representable, self.forward_smallest_num_representable)\n",
        "        b2  = self.bn2(c2q)\n",
        "        b2q = optimized_tensor_fp_quantize(b2, self.forward_step_size, self.forward_largest_num_representable, self.forward_smallest_num_representable)\n",
        "        a2  = self.act2(b2q)\n",
        "        p2  = self.pool2(a2)\n",
        " \n",
        "        # Flatten and Layer 3\n",
        "        flt = p2.view(p2.size(0), -1)\n",
        "        out = self.lin2(flt)\n",
        "        out_new = optimized_tensor_fp_quantize(out, self.forward_step_size, self.forward_largest_num_representable, self.forward_smallest_num_representable)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "8t8Zej6m3ufg"
      },
      "outputs": [],
      "source": [
        "class QuantizedConvNet(nn.Module):\n",
        "    def __init__(self, model_fp32):\n",
        "        super(QuantizedConvNet, self).__init__()\n",
        "        # QuantStub converts tensors from floating point to quantized.\n",
        "        # This will only be used for inputs.\n",
        "        self.quant = torch.quantization.QuantStub()\n",
        "        # DeQuantStub converts tensors from quantized to floating point.\n",
        "        # This will only be used for outputs.\n",
        "        self.dequant = torch.quantization.DeQuantStub()\n",
        "        # FP32 model\n",
        "        self.model_fp32 = model_fp32\n",
        "\n",
        "    def forward(self, x):\n",
        "        # manually specify where tensors will be converted from floating\n",
        "        # point to quantized in the quantized model\n",
        "        x = self.quant(x)\n",
        "        x = self.model_fp32(x)\n",
        "        # manually specify where tensors will be converted from quantized\n",
        "        # to floating point in the quantized model\n",
        "        x = self.dequant(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGjcFMQ5XjMj"
      },
      "source": [
        "# Test Code Here\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "RjT2c_f9XjMk"
      },
      "outputs": [],
      "source": [
        "# Hyper Parameter for FashionMNIST\n",
        "input_size = 784\n",
        "num_classes = 10\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example of instantiating a model, training it with given hyperparameters, etc"
      ],
      "metadata": {
        "id": "5kUXftre3oYu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "id": "IlnS6XwxXjMk",
        "outputId": "5bf3c2d3-1958-42b0-c382-0d7522259f85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "64\n",
            "32\n",
            "---Training started\n",
            "Epoch: [ 1/ 5], Step: [ 600/ 1875], Loss: 0.3993\n",
            "Epoch: [ 1/ 5], Step: [ 1200/ 1875], Loss: 0.4763\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-0b84a64151b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;31m# Training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquantize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m   \u001b[0;31m# Need to quantize the model afterwards\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-55-6538acb9510c>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(arg, model, criterion, optimizer, train_loader, quantize)\u001b[0m\n\u001b[1;32m     47\u001b[0m                     \u001b[0;31m# print(gradient)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;31m# # TODO: Need to quantize the biases as well.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    169\u001b[0m                  \u001b[0mmaximize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'maximize'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m                  \u001b[0mforeach\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'foreach'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m                  capturable=group['capturable'])\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    224\u001b[0m          \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m          \u001b[0mmaximize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m          capturable=capturable)\n\u001b[0m\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable)\u001b[0m\n\u001b[1;32m    303\u001b[0m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m             \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "args = easydict.EasyDict({\n",
        "        \"batch_size\": 32,\n",
        "        \"epochs\": 5,\n",
        "        \"lr\": 0.001,\n",
        "        \"enable_cuda\" : True,\n",
        "        \"L1norm\" : False,\n",
        "        \"simpleNet\" : True,\n",
        "        \"activation\" : \"relu\", #relu, tanh, sigmoid\n",
        "        \"train_curve\" : True, \n",
        "        \"optimization\" :\"Adam\"\n",
        "})\n",
        "\n",
        "# Dataset Loader (Input Pipeline)\n",
        "quantize = True\n",
        "train_loader = torch.utils.data.DataLoader(dataset = train_set, batch_size = args.batch_size, shuffle = True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset = test_set, batch_size = args.batch_size, shuffle = False)\n",
        "\n",
        "num_bits_test = [64, 32, 16, 8, 4]\n",
        "num_fractional_bits = [32, 16, 8, 4, 2]\n",
        "acc = []\n",
        "\n",
        "for (num_bits,num_fractional_bits) in zip(num_bits_test, num_fractional_bits):\n",
        "  print(num_bits)\n",
        "  print(num_fractional_bits)\n",
        "  forwardfp= (num_bits, num_fractional_bits) \n",
        "  gradientfp= (num_bits, num_fractional_bits) \n",
        "  lossfp= (num_bits, num_fractional_bits) \n",
        "  weightsfp= (num_bits, num_fractional_bits) \n",
        "  biasfp=(num_bits, num_fractional_bits) \n",
        "\n",
        "  # Declare Model\n",
        "  model = MyConvNet_FIXED_POINT(args, forwardfp, gradientfp, lossfp, weightsfp, biasfp).cuda()\n",
        "  #model = MyConvNet_FP32(args).cuda()\n",
        "\n",
        "  criterion = nn.CrossEntropyLoss().cuda()\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr = args.lr) \n",
        "\n",
        "  # Training\n",
        "  train_model(args, model, criterion, optimizer, train_loader, quantize)\n",
        "\n",
        "  # Need to quantize the model afterwards\n",
        "  quantize_fp_model_weights(model)\n",
        "\n",
        "  # Testing ARC\n",
        "  test_acc, test_loss = get_acc(model, criterion, test_loader, quantize)\n",
        "  print(\"Test Accuracy: {}\".format(test_acc))\n",
        "  print(\"Test Loss: {}\".format(test_loss))\n",
        "\n",
        "  acc.append(test_acc.item())\n",
        "\n",
        "plt.figure(0)\n",
        "plt.plot(num_bits_test, acc)\n",
        "plt.title(\"Varying Number of Quantized Bits\")\n",
        "plt.xlabel(\"Number of Quantized Bits\")\n",
        "plt.ylabel(\"Acc (%)\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "forwardfp= (16, 8) \n",
        "gradientfp= (16, 10) \n",
        "lossfp= (16, 10) \n",
        "weightsfp= (32, 12) \n",
        "biasfp=(64, 32) \n",
        "\n",
        "# Declare Model\n",
        "model = MyConvNet_FIXED_POINT(args, forwardfp, gradientfp, lossfp, weightsfp, biasfp).cuda()\n",
        "#model = MyConvNet_FP32(args).cuda()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss().cuda()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = args.lr) \n",
        "\n",
        "# Training\n",
        "train_model(args, model, criterion, optimizer, train_loader, quantize)\n",
        "\n",
        "# Need to quantize the model afterwards\n",
        "quantize_fp_model_weights(model)\n",
        "\n",
        "# Testing ARC\n",
        "test_acc, test_loss = get_acc(model, criterion, test_loader, quantize)\n",
        "print(\"Test Accuracy: {}\".format(test_acc))\n",
        "print(\"Test Loss: {}\".format(test_loss))\n"
      ],
      "metadata": {
        "id": "V_GNEm1r5BAK",
        "outputId": "13f74335-8a2a-4e42-fb95-21106035c2b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---Training started\n",
            "Epoch: [ 1/ 5], Step: [ 600/ 1875], Loss: 0.6924\n",
            "Epoch: [ 1/ 5], Step: [ 1200/ 1875], Loss: 0.7031\n",
            "Epoch: [ 1/ 5], Step: [ 1800/ 1875], Loss: 0.1729\n",
            "Epoch: [ 2/ 5], Step: [ 600/ 1875], Loss: 0.2891\n",
            "Epoch: [ 2/ 5], Step: [ 1200/ 1875], Loss: 0.2002\n",
            "Epoch: [ 2/ 5], Step: [ 1800/ 1875], Loss: 0.4658\n",
            "Epoch: [ 3/ 5], Step: [ 600/ 1875], Loss: 0.2021\n",
            "Epoch: [ 3/ 5], Step: [ 1200/ 1875], Loss: 0.3037\n",
            "Epoch: [ 3/ 5], Step: [ 1800/ 1875], Loss: 0.0977\n",
            "Epoch: [ 4/ 5], Step: [ 600/ 1875], Loss: 0.1113\n",
            "Epoch: [ 4/ 5], Step: [ 1200/ 1875], Loss: 0.4414\n",
            "Epoch: [ 4/ 5], Step: [ 1800/ 1875], Loss: 0.1992\n",
            "Epoch: [ 5/ 5], Step: [ 600/ 1875], Loss: 0.3311\n",
            "Epoch: [ 5/ 5], Step: [ 1200/ 1875], Loss: 0.1680\n",
            "Epoch: [ 5/ 5], Step: [ 1800/ 1875], Loss: 0.1729\n",
            "Test Accuracy: 93.75\n",
            "Test Loss: 0.359375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fp_32model = MyConvNet_FP32(args).cuda()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss().cuda()\n",
        "optimizer = torch.optim.Adam(fp_32model.parameters(), lr = args.lr) \n",
        "\n",
        "train_model(args, fp_32model, criterion, optimizer, train_loader, False)\n",
        "\n",
        "test_acc, test_loss = get_acc(fp_32model, criterion, test_loader, False)\n",
        "print(\"Test Accuracy: {}\".format(test_acc))\n",
        "print(\"Test Loss: {}\".format(test_loss))"
      ],
      "metadata": {
        "id": "RNiHelhk31Zj",
        "outputId": "0746e68f-b48b-45ff-b6ec-6ffd940b833a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---Training started\n",
            "Epoch: [ 1/ 5], Step: [ 600/ 1875], Loss: 0.3771\n",
            "Epoch: [ 1/ 5], Step: [ 1200/ 1875], Loss: 0.4219\n",
            "Epoch: [ 1/ 5], Step: [ 1800/ 1875], Loss: 0.3681\n",
            "Epoch: [ 2/ 5], Step: [ 600/ 1875], Loss: 0.3782\n",
            "Epoch: [ 2/ 5], Step: [ 1200/ 1875], Loss: 0.3302\n",
            "Epoch: [ 2/ 5], Step: [ 1800/ 1875], Loss: 0.4099\n",
            "Epoch: [ 3/ 5], Step: [ 600/ 1875], Loss: 0.5968\n",
            "Epoch: [ 3/ 5], Step: [ 1200/ 1875], Loss: 0.2400\n",
            "Epoch: [ 3/ 5], Step: [ 1800/ 1875], Loss: 0.3695\n",
            "Epoch: [ 4/ 5], Step: [ 600/ 1875], Loss: 0.2213\n",
            "Epoch: [ 4/ 5], Step: [ 1200/ 1875], Loss: 0.1097\n",
            "Epoch: [ 4/ 5], Step: [ 1800/ 1875], Loss: 0.3762\n",
            "Epoch: [ 5/ 5], Step: [ 600/ 1875], Loss: 0.0675\n",
            "Epoch: [ 5/ 5], Step: [ 1200/ 1875], Loss: 0.2744\n",
            "Epoch: [ 5/ 5], Step: [ 1800/ 1875], Loss: 0.1331\n",
            "Test Accuracy: 87.5\n",
            "Test Loss: 0.6163979172706604\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4z9Q0vi95Alz"
      },
      "source": [
        "## Preston's Training of Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fgEQBWHy5FD-"
      },
      "outputs": [],
      "source": [
        "# cuda_device = torch.device(\"cuda:0\")\n",
        "# cpu_device = torch.device(\"cpu:0\")\n",
        "\n",
        "# # Initial model\n",
        "# FP_model = MyConvNet_FP32(args).cuda()\n",
        "# FP_fused_model = MyConvNet_FP32(args)\n",
        "\n",
        "# # Training stuff\n",
        "# criterion = nn.CrossEntropyLoss().cuda()\n",
        "# optimizer = torch.optim.SGD(FP_model.parameters(), lr = learning_rate) \n",
        "\n",
        "# train_model(FP_model, criterion, optimizer, train_loader)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P63UTvuTHjKT"
      },
      "outputs": [],
      "source": [
        "# test_acc_FP, test_loss_FP = get_acc(FP_model, criterion, test_loader)\n",
        "# print(\"Test Accuracy: {}\".format(test_acc_FP))\n",
        "# print(\"Test Loss: {}\".format(test_loss_FP))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rJYZN0ky_9i6"
      },
      "outputs": [],
      "source": [
        "\n",
        "# copy_models(FP_model,FP_fused_model)   \n",
        "# fuse_conv_bn(FP_model,FP_fused_model)\n",
        "\n",
        "# quantized_model = QuantizedConvNet(model_fp32=FP_fused_model).to(cpu_device)\n",
        "\n",
        "# quantization_config = torch.quantization.get_default_qconfig(\"fbgemm\")\n",
        "# quantized_model.qconfig = quantization_config\n",
        "# torch.quantization.prepare_qat(quantized_model, inplace=True)\n",
        "\n",
        "# quantized_model.to(cuda_device)\n",
        "# train_model(quantized_model, criterion, optimizer, train_loader)\n",
        "# # quantized_model.to(cpu_device)\n",
        "\n",
        "# # quantized_model = torch.quantization.convert(quantized_model, inplace=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QhdEVwvJHnhl"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# test_acc, test_loss = get_acc(quantized_model, criterion, test_loader)\n",
        "# print(\"Test Accuracy: {}\".format(test_acc))\n",
        "# print(\"Test Loss: {}\".format(test_loss))\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}