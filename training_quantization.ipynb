{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Source Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imports Needed Throughout the Project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# All Imports \n",
        "import sys\n",
        "import numpy as np\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "from google.colab import files\n",
        "\n",
        "# argument parser\n",
        "import easydict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Get and Download Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# MNIST Dataset (Images and Labels)\n",
        "train_set = dsets.FashionMNIST(\n",
        "    root = './data/FashionMNIST',\n",
        "    train = True,\n",
        "    download = True,\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor()                                 \n",
        "    ])\n",
        ")\n",
        "\n",
        "test_set = dsets.FashionMNIST(\n",
        "    root = './data/FashionMNIST',\n",
        "    train = False,\n",
        "    download = True,\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor()                                 \n",
        "    ])\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## More Helper Code for Training and Testing Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_model(model, criterion, optimizer, train_loader):\n",
        "    print(\"---Training started\")\n",
        "    # Training the Model\n",
        "    for epoch in range(num_epochs):\n",
        "        for i, (images, labels) in enumerate(train_loader):\n",
        "            # Load Images into GPU\n",
        "            images = images.cuda()\n",
        "            labels = Variable(labels).cuda()\n",
        "\n",
        "            # Forward + Backward + Optimize\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            L1norm = model.parameters()\n",
        "            arr = []\n",
        "\n",
        "            # Calculate L1 Norm (if included in hyperparameters)\n",
        "            if args.L1norm == True:\n",
        "                for name,param in model.named_parameters():\n",
        "                    if 'weight' in name.split('.'):\n",
        "                        arr.append(param)\n",
        "\n",
        "                L1loss = 0\n",
        "                for Losstmp in arr:\n",
        "                    L1loss = L1loss+Losstmp.abs().mean()\n",
        "\n",
        "                if len(arr) > 0:\n",
        "                    loss = loss+L1loss/len(arr)\n",
        "\n",
        "            # Optimizer Step, Propagate Loss backwards\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if (i + 1) % 600 == 0:\n",
        "                print('Epoch: [% d/% d], Step: [% d/% d], Loss: %.4f'\n",
        "                        % (epoch + 1, num_epochs, i + 1,\n",
        "                        len(train_set) // batch_size, loss.data.item()))\n",
        "\n",
        "\n",
        "# Gets accuracy given dataset as well as total test loss\n",
        "def get_acc(model, criterion, test_loader):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for images, labels in test_loader:\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        outputs = model(images)\n",
        "        testloss = criterion(outputs, labels)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum()\n",
        "        break\n",
        "\n",
        "    return ((100 * correct / total), testloss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## FP32 Model "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MyConvNet_FP32(nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super(MyConvNet_FP32, self).__init__()\n",
        "        # Layer 1\n",
        "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn1   = nn.BatchNorm2d(16)\n",
        "        self.act1  = nn.ReLU(inplace=True)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        # Layer 2\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn2   = nn.BatchNorm2d(32)\n",
        "        self.act2  = nn.ReLU(inplace=True)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        # Layer 3\n",
        "        self.lin2  = nn.Linear(7*7*32, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Layer 1\n",
        "        c1 = self.conv1(x)\n",
        "        b1  = self.bn1(c1)\n",
        "        a1  = self.act1(b1)\n",
        "        p1  = self.pool1(a1)\n",
        "\n",
        "        # Layer 2\n",
        "        c2  = self.conv2(p1)\n",
        "        b2  = self.bn2(c2)\n",
        "        a2  = self.act2(b2)\n",
        "        p2  = self.pool2(a2)\n",
        "\n",
        "        # Flatten and Layer 3\n",
        "        flt = p2.view(p2.size(0), -1)\n",
        "        out = self.lin2(flt)\n",
        "        return out\n",
        "  \n",
        "# model = MyConvNet(args)\n",
        "# model = model.cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Quantization Helper Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def simple_quantize_val(val, scale_factor, min_val, max_val):\n",
        "  value = torch.round(val / scale_factor)\n",
        "\n",
        "  if (value < min_val):\n",
        "    value = min_val\n",
        "\n",
        "  if (value > max_val):\n",
        "    value = max_val\n",
        "\n",
        "  return (value * scale_factor)\n",
        "\n",
        "# NOTE THIS IS THE ONE THAT WE WILL USE\n",
        "def fixed_point_quantize_val(val, num_bits, fractional_bits):\n",
        "  integer_bits = num_bits - fractional_bits - 1 # Subtract one for sign bit\n",
        "  smallest_step_size = 1 / np.power(2, fractional_bits)\n",
        "  largest_number = (np.power(2, integer_bits) - 1) + ((np.power(2, fractional_bits)-1) * smallest_step_size)\n",
        "  smallest_number = -1 * np.power(2, integer_bits)\n",
        "\n",
        "  value = torch.round(val / smallest_step_size) * smallest_step_size\n",
        "\n",
        "  if (value < smallest_number):\n",
        "    value = smallest_number\n",
        "\n",
        "  if (value > largest_number):\n",
        "    value = largest_number\n",
        "\n",
        "  return value\n",
        "\n",
        "# Gets global min and max\n",
        "def get_min_max_weight_val(model):\n",
        "  cnt = 0\n",
        "  global_max = -np.inf\n",
        "  global_min = np.inf\n",
        "\n",
        "  # Loop through layers and get global min and max of weights\n",
        "  for layer in model.modules():\n",
        "    if not isinstance(layer, (nn.ReLU, nn.MaxPool2d))and cnt != 0:\n",
        "      local_max = torch.max(layer.weight).data\n",
        "      local_min = torch.min(layer.weight).data\n",
        "\n",
        "      if local_max > global_max:\n",
        "        global_max = local_max\n",
        "      \n",
        "      if local_min < global_min:\n",
        "        global_min = local_min\n",
        "\n",
        "    cnt+=1\n",
        "\n",
        "  return global_max, global_min "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Quantization Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Assume that we always \n",
        "class MyConvNet_FIXED_POINT(nn.Module):\n",
        "    def __init__(self, args, num_bits, num_fractional_bits):\n",
        "        super(MyConvNet_FP32, self).__init__()\n",
        "\n",
        "        # Fixed Point Parameters\n",
        "        self.fp_bits = num_bits\n",
        "        self.sign_bit = 1\n",
        "        self.integer_bits = (num_bits - 1 - num_fractional_bits)\n",
        "        self.fractional_bits = num_fractional_bits\n",
        "\n",
        "        # Layer 1\n",
        "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn1   = nn.BatchNorm2d(16)\n",
        "        self.act1  = nn.ReLU(inplace=True)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        # Layer 2\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn2   = nn.BatchNorm2d(32)\n",
        "        self.act2  = nn.ReLU(inplace=True)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        # Layer 3\n",
        "        self.lin2  = nn.Linear(7*7*32, 10)\n",
        "\n",
        "\n",
        "    # AUGMENT FORWARD PASS. forward pass not quantizes every single time we go through\n",
        "    def forward(self, x):\n",
        "        # Layer 1\n",
        "        c1 = self.conv1(x)\n",
        "        print(c1.size)\n",
        "        b1  = self.bn1(c1)\n",
        "        a1  = self.act1(b1)\n",
        "        p1  = self.pool1(a1)\n",
        "\n",
        "        # Layer 2\n",
        "        c2  = self.conv2(p1)\n",
        "        b2  = self.bn2(c2)\n",
        "        a2  = self.act2(b2)\n",
        "        p2  = self.pool2(a2)\n",
        "\n",
        "        # Flatten and Layer 3\n",
        "        flt = p2.view(p2.size(0), -1)\n",
        "        out = self.lin2(flt)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Test Code Here\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "args = easydict.EasyDict({\n",
        "        \"batch_size\": 1,\n",
        "        \"epochs\": 3,\n",
        "        \"lr\": 0.001,\n",
        "        \"enable_cuda\" : True,\n",
        "        \"L1norm\" : False,\n",
        "        \"simpleNet\" : True,\n",
        "        \"activation\" : \"relu\", #relu, tanh, sigmoid\n",
        "        \"train_curve\" : True, \n",
        "        \"optimization\" :\"SGD\"\n",
        "})\n",
        "\n",
        "# Hyper Parameter for FashionMNIST\n",
        "input_size = 784\n",
        "num_classes = 10\n",
        "num_epochs = args.epochs\n",
        "batch_size = args.batch_size\n",
        "learning_rate = args.lr\n",
        "\n",
        "# Dataset Loader (Input Pipeline)\n",
        "train_loader = torch.utils.data.DataLoader(dataset = train_set, batch_size = batch_size, shuffle = True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset = test_set, batch_size = batch_size, shuffle = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = MyConvNet_FIXED_POINT(args, 8, 5).cuda()\n",
        "criterion = nn.CrossEntropyLoss().cuda()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate) \n",
        "\n",
        "get_acc(model, criterion, test_loader)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyO0Bc7nlOA76q5Bpr79fqJu",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
